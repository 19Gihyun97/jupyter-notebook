{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f342bf21-7f43-4493-bf96-b3c9fb5a53de",
   "metadata": {},
   "source": [
    "# ▶ 함수 = 특정한 기능을 하는 상자\n",
    "패키지 = 함수(특정한 기능을 하는 상자)가 여러 개 들어 있는 꾸러미  \n",
    "모듈 = 패키지라는 큰 꾸러미에 비슷한 함수들을 넣어둔 작은 꾸러미들. ex) 머신러닝 모델 평가 sklearn 패키지에는 metrics, tree 등의 여러 모듈이 있다.  \n",
    "★ 모듈에 들어 있는 함수를 사용 => 패키지명.모듈명.함수명() 입력  \n",
    "★ 모듈의 함수를 사용할 때 매번 패키지명, 모듈명을 입력하는 것이 번거로울경우\n",
    "=> from 패키지명.모듈명 import 함수명 으로 함수를 직접 로드하면 된다. 함수를 직접 로드하면 함수를 사용할 때 함수명만 입력 \n",
    "\n",
    "★ 패키지 가져오기(로드 = 패키지를 사용할 수 있도록 불러들이는 작업)  \n",
    "- import pandas as pd   \n",
    "- import numpy as np  \n",
    "- import seaborn as sns # 시각화 라이브러리, 그래프 패키지 가져오기  \n",
    "- import matplotlip.pyplot as plt # 시각화 패키지 가져오기  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d712515-db33-44fd-a240-ac02fcc35d2a",
   "metadata": {},
   "source": [
    "## ▷ 데이터 복사하기    \n",
    "df.copy()  \n",
    "df_1 = df.copy()  \n",
    "df_1  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac38493-00e6-417b-bf38-478f1f19f031",
   "metadata": {},
   "source": [
    "## ▷ 변수 이름 바꾸기\n",
    "df.rename\n",
    "\n",
    "df = df.rename(columns = {'이름' : '바꿀이름', '이름' : '바꿀이름'}) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfd2499-8afb-4da2-b8f2-859856ca8c7c",
   "metadata": {},
   "source": [
    "## ▷ 파생변수 추가하기\n",
    "df.assing\n",
    "\n",
    "★ 파생변수 추가하기 \n",
    "df.assing\n",
    "ex) exam.assign(total = exam['math'] + exam['english'] + exam['science'])\n",
    "\n",
    "★ 여러 파생변수 한 번에 추가하기 ,(쉼표)를 이용해 새변 수명과 변수를 만드는 공식 나열\n",
    "exam.assign(total = exam['math'] + exam['english'] + exam['science'], # total 추가\n",
    "           mean = (exam['math'] + exam['english'] + exam['science']) / 3) # mean 추가\n",
    "\n",
    "★ 조건에 따른 다른 값을 부여한 변수 추가하기\n",
    "np.where()\n",
    "\n",
    "df.assign(새 변수명 = np.where(df['변수명'] > (조건), '조건에 해당하면 이것', '아닐 시 이것'\n",
    "ex) exam.assign(test = np.where(exam['science'] >= 60, 'pass', 'fail'))\n",
    "### np.where(exam['science'] >= 60, 'pass', 'fail') 라는 조건을 넣어서 새로운 파생 변수를 추가함\n",
    "### 'pass', 'fail' 의 조건을 넣었음\n",
    "\n",
    "★★★★★ 중요\n",
    "df.assign 사용 시 \n",
    "ex) cus = cus.assign 이렇게 cus에 다시 넣어줘야 실제로 cus 안에 추가된다.\n",
    "\n",
    "조건이 여러개\n",
    "ex) df.assign(새 변수명 = np.where((df[변수명'] < 30) & (df['변수명'] >= 20), '20대', ''))\n",
    "\n",
    "★ 데이터 프레임명 줄여 쓰기\n",
    "lambda 를 이용하면 데이터 프레임명 대신 약어를 입력해 코드를 간결하게 작성할 수 있다.\n",
    "lambda x 는 데이터 프레임명 자리에 x를 입력하겠다는 의미이다.\n",
    "ex) df.assign(new = lambda x : x['math'] + x['english'] + x['science'])\n",
    "\n",
    "★ 새로운 변수 추가하기\n",
    "df['추가할 변수 명'] = df['변수1'] + df['변수2']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b587b8-36c0-42de-8c5b-20cfd19e6748",
   "metadata": {},
   "source": [
    "## ▷\n",
    "★ 요약 통계량 df.describe() ★\n",
    "\n",
    "출력값 - 통계량 - 설명\n",
    "count - 빈도(frequency) -값의 개수\n",
    "mean - 평균(mean) - 모든 값을 더해 값의 개수로 나눈 값\n",
    "std - 표준편차(standard deviation) - 변수의 값들이 평균에서 떨어진 정도를 나타낸 값\n",
    "min - 최소값(minimum) - 가장 작은 값\n",
    "25% - 1사분위수(1st quantile) - 하위 25%(4분의 1) 지점에 위치한 값\n",
    "50% - 중앙값(median) - 하위 50%(중앙) 지점에 위치한 값\n",
    "75% - 3사분위수(3rd quantile) - 하위 75%(4분의 3) 지점에 위치한 값\n",
    "max - 최대값(maximum) - 가장 큰 값\n",
    "\n",
    "★ 표준편차 : 표준(평균 점수)으로부터 흩어진 정도\n",
    "ex) 1반의 점수 = [58, 60, 62] 평균 60\n",
    "    2반의 점수 = [30, 60, 90] 평균 60\n",
    "표준편차가 작다 => 1반처럼 평균을 중심으로 뭉쳐있다.\n",
    "표준편차가 크다 => 2반처럼 평균을 중심으로 뭉쳐있지 않고 흩어져 있다. \n",
    "\n",
    "★ 문자로 된 변수의 요약 통계량을 함께 출력하려면 describe()에 include = ‘all’ 입력\n",
    "ex) mpg.describe(include = ‘all’)\n",
    "# 문자 변수 요약 통계량 함께 출력\n",
    "\n",
    "\n",
    "(출력값) - (통계량) - (설명)\n",
    "count - 빈도 - 값의 개수\n",
    "unique - 고유값 빈도 - 중복을 제거한 범주의 개수\n",
    "top - 최빈값 -개수가 가장 많은 값\n",
    "freq - 최빈값 빈도 - 개수가 가장 많은 값의 개수\n",
    "\n",
    "★ unique, top, freq 는 문자 변수로만 계산하므로 숫자 변수에는 NaN 이 출력됩니다.\n",
    "반대로 숫자를 이용해 계산하는 요약 통계량은 숫자 변수에만 출력되고 문자 변수에는 NaN이 출력됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1f3b13-489e-4eee-8fec-c4db695211c9",
   "metadata": {},
   "source": [
    "## ▷ 데이터 재구조화\n",
    "pd.crosstab - 데이터 재구조화 (교차표 - 피벗테이블의 한종류)\n",
    "\n",
    "개수 파악이나 수치형 데이터를 넣어 계산\n",
    "\n",
    "ex)\n",
    "pd.crosstab(index = [data.변수, data.변수], columns = data.날짜)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ae71b-dc5f-4ae1-8c96-55d942f665fc",
   "metadata": {},
   "source": [
    "## ▷ 데이터 정리\n",
    "★ 내림차순 정렬 \n",
    "\n",
    "ascending = False\n",
    "\n",
    "ex) df.sort_values('변수', ascending = False)  # 변수 내림차순 정렬\n",
    "\n",
    "★ 결측치를 다른 값으로 대체하기\n",
    "df.fillna()\n",
    "\n",
    "★ 결측치 확인\n",
    "pd.isna()\n",
    "데이터에 결측치(NaN)가 들어 있는지 알 수 있다.\n",
    "ex) pd.isna(df).sum()  # 결측치 빈도 확인\n",
    "\n",
    "\n",
    "★ 변수의 속성, df.info()  ★\n",
    "결측치 확인 가능\n",
    "\n",
    "\n",
    "★ 결측 처리하기\n",
    "\n",
    "np.where() == 값, np.nan  \n",
    "ex) df['변수'] = np.where(df['변수'] == 3, np.nan, df['변수'])  \n",
    "변수의 값이 3이면 결측처리한다.  \n",
    "\n",
    "★ 결측치가 있는 행 제거하기 \n",
    "df.dropna()  \n",
    "\n",
    "ex) df.dropna(subset = ['변수'])  # 변수 결측치 제거  \n",
    "\n",
    "★ 결측치가 하나라도 있으면 제거하기  \n",
    "데이터명 = df.dropna()  # 모든 변수에 결측치 없는 데이터 추출  \n",
    "데이터명  \n",
    "주의! = 이 방법은 결측치가 하나라도 있으면 모두 제거하므로 간편하지만, 분석에 필요한 행까지 손실된다는 단점이 있다.  \n",
    "그러므로 분석에 사용할 변수를 직접 지정해 결측치를 제거하는 방법을 사용하자  \n",
    "\n",
    "데이터가 작고 결측치가 많을 때는 결측치를 제거하면 너무 많은 데이터가 손실되어 분석 결과가 왜곡되는 문제가 생긴다.  \n",
    "결측치를 제거하는 대신 다른 값을 채워 넣는 방법이 있다 이를 결측치 대체법이라고 한다.  \n",
    "\n",
    "결측치를 대체하는 방법에는  \n",
    "평균값이나 최빈값 같은 대표값을 구해 모든 결측치를 하나의 값으로 일괄 대체하는 방법과     \n",
    "통계 분석 기법으로 결측치의 예측값을 추정해 대체하는 방법이 있다.  \n",
    "평균값을 구해 대체하는 방법  \n",
    "\n",
    "★ df.fillna()  \n",
    "()안에 결측치를 대체할 값을 입력하면 된다.  \n",
    "\n",
    "ex) df['math'] = df['math'].fillna(10)  # math 변수가 NaN이면 10으로 대체  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a8e120-aa8e-4044-8575-0b77a37276f3",
   "metadata": {},
   "source": [
    "## ▷ 변수 그룹별로 나누기\n",
    "\n",
    "1. import warnings\n",
    "warnings.filterwarnings('ignore') - 오류 무시하기\n",
    "\n",
    "2. 큰 숫자 먼저 미만을 사용 & 다음 숫자 사용    \n",
    "ex) cus_0['Age']<30) & (cus_0['Age']>=20) 30먼저 이후 20    \n",
    "\n",
    "cus_0 = cus.copy()  \n",
    "cus_0['Ages'] = ''  \n",
    "cus_0['Ages'][(cus_0['Age']<30) & (cus_0['Age']>=20)] = '20대'  \n",
    "cus_0['Ages'][(cus_0['Age']<40) & (cus_0['Age']>=30)] = '30대'  \n",
    "cus_0['Ages'][(cus_0['Age']<50) & (cus_0['Age']>=40)] = '40대'  \n",
    "cus_0['Ages'][(cus_0['Age']<60) & (cus_0['Age']>=50)] = '50대'  \n",
    "cus_0['Ages'][(cus_0['Age']>=60)] = '60대 이상'  \n",
    "cus_0  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e87470-4561-44d7-9432-1ca96ee80a73",
   "metadata": {},
   "source": [
    "## ▷ 타입 바꾸기\n",
    "\n",
    "문자열의 데이터 타입을 계산 가능하도록 int로 바꾸기  \n",
    "df['변수'] = df['변수'].astype('int64') - 실수로 바꾸기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa2245-1818-44cb-93a9-4feb55336d48",
   "metadata": {},
   "source": [
    "## ▷ 값의 개수 구하기, len() \n",
    "\n",
    "x = [1, 2, 3, 4, 5]\n",
    "\n",
    "len(x)\n",
    "5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6df7ce5-87db-4921-a140-defc40e2242f",
   "metadata": {},
   "source": [
    "## ▷ 데이터 실제 반영\n",
    "inplace = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98508f0-2566-4d22-9268-74f0248ad265",
   "metadata": {},
   "source": [
    "## ▷ df.replace  \n",
    "\n",
    "ex) df.replace({'col_1' : {'PhD' : '박사'}})  \n",
    "'Education' 변수 안에 phd 값이 박사로 변경  \n",
    "\n",
    "여러 변수 안의 값 변경  \n",
    "cus.replace({'col_1' : {'PhD' : '박사'}, 'col_2' : {'Graduation' : '학사'}})  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1626652-9cfd-4a43-9069-af1d9d7f6616",
   "metadata": {},
   "source": [
    "## ▷ ★ 변수를 인덱스로 바꾸지 않기 ★  \n",
    "df.groupby()에 as_index = False 를 입력하면 변수를 인덱스로 바꾸지 않고 원래도 유지한다.  \n",
    "ex) df.groupby('변수', as_index = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83eb6148-741d-4e9e-b0ff-0ac3d32258b8",
   "metadata": {},
   "source": [
    "## ▷ ★ 빈도표(변수의 값이 종류별로 몇 개씩 있는지, 값의 개수를 나타낸 값), df.value_counts() ★\n",
    "\n",
    "df['tset'].value_counts()\n",
    "\n",
    "pass 128\n",
    "fail 106\n",
    "\n",
    "df.value_counts().sort_index()\n",
    ".sort_index()를 적용하면 빈도 기준으로 내림차순 정렬하지 않고 변수의 값 순서로 정렬합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc36e267-3cb7-4e8e-a11e-a96f8c6c08af",
   "metadata": {},
   "source": [
    "## ▷ ★ 상관분석 - 두 변수의 관계 분석하기\n",
    "두 연속 변수가 서로 관련이 있는지 검정하는 통계 분석 기법\n",
    "상관계수는 0~1사이의 값을 지니며 1에 가까울수록 관련성이 크다\n",
    "상관계수가 양수면 정비례, 음수면 반비례\n",
    "\n",
    "df.corr()\n",
    "\n",
    "상관계수(소득과 지출)   \n",
    "cus_high_1 = cus_high.corr() # 상관행렬만들기  \n",
    "cus_high_1 = round(cus_high_1, 2) # 소수점 둘째 자리까지 반올림  \n",
    "cus_high_1  \n",
    "['Income'], ['Spending']  \n",
    "상관계수가 0보단 1에 가까워 완벽하진 않지만 양의 상관관계를 갖는 것을 확인  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e35b1-b464-4bd0-9ffb-83b8e135dc8c",
   "metadata": {},
   "source": [
    "## ▷ ★ 유의확률\n",
    "유의확률은 scipy(사이피) 패키지의 stats.pearsonr()을 이용해 구할 수 있다.\n",
    "\n",
    "from scipy import stat\n",
    "stats.pearsonr(df['변수명'], df['변수명'])\n",
    "(첫번째 값(상관계수), 두번째 값(유의확률)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd64fb-7b3b-4329-93fd-e67ecf690c6b",
   "metadata": {},
   "source": [
    "## ▷ ★ 집단별로 요약하기, df.groupby(), df.egg() ★\n",
    "\n",
    "ex) 수학 점수 평균하기\n",
    "df.agg(mean_math = ('math', 'mean'))\n",
    "1. 요약값을 할당할 변수명은 자유롭게 정하고 따옴표('')는 입력하지 않는다.\n",
    "2. 요약하는데 사용할 '변수명'과 '함수명'은 따옴표('')로 감싸 문자형태로 입력한다.\n",
    "3. 함수명 뒤에 ()를 넣지 않으니 주의\n",
    "\n",
    "df.groupby() 에 변수를 지정하면 변수의 범주별로 데이터를 분리한다.\n",
    "df.groupby('변수').agg(데이터이름 = ('변수명', '함수명'))\n",
    "                            (데이터 이름은 아무렇게나 짓는다.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e4dae-3fa4-4dc2-81a5-532897fb5e9d",
   "metadata": {},
   "source": [
    "## ▷ ★ 첫 번째 행 변수명 아닌 데이터로 인식, header = None ★\n",
    "\n",
    "df = pd.read_excel(df.xlsx, header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16bc4f4-d76b-44b7-a7e3-0110ee0b7f0d",
   "metadata": {},
   "source": [
    "## ▷ ★ 필요한 데이터만 추출하기, df.query ★ \n",
    "파이썬의 같다 == \n",
    "\n",
    "df.query('변수 == 10') # 변수가 10인 경우\n",
    "df.query('변수 != 10') # 변수가 10이 아닌 경우 같지 않다 => !=\n",
    "df.query('변수 >= 10') # 변수가 10이상인 경우\n",
    "\n",
    "★ 여러 조건을 충족하는 행 추출하기\n",
    "\n",
    "1. 그리고(and) &  => 여러 조건을 동시에 충족하는 행 추출\n",
    "df.query('변수1 == 10 & 변수2 >= 50') # 변수1이 10이고 변수2가 50이상인 경우\n",
    "\n",
    "2. 또는(or) |  => 여러 조건 중 하나라도 충족하는 데이터를 추출\n",
    "df.query('변수1 == 10 | 변수2 >= 50') # 변수1이 10이거나 변수2가 50이상인 경우  \n",
    "\n",
    "★ 목록에 해당하는 행 추출하기  \n",
    "변수의 값이 지정한 목록에 해당될 경우만 추출해야 할 때  \n",
    "df.query('변수1 == 1 | 변수1 == 3 | 변수1 == 5')  \n",
    "  \n",
    "=> in[] 을 이용하면 코드를 좀더 간결하게 작성할 수 있다.  \n",
    "in은 변수 값이 리스트[]에 입력한 목록에 해당되는지 확인하는 기능을 한다.  \n",
    "df.query('변수1 in [1, 3, 5]')  \n",
    "\n",
    "★ 문자 변수(' ')를 이용해 조건에 맞는 행 추출하기  \n",
    "query()에 전체 조건을 감싸는 따옴표와 추출할 문자를 감싸는 따옴표를 서로 다른 모양으로 입력해야 한다.  \n",
    "ex) df.query('sex == \"F\" & country == \"Korea\"')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf57863f-1081-4874-8bda-2c404cc91ee0",
   "metadata": {},
   "source": [
    "## ▷"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
